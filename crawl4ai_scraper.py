#!/usr/bin/env python3
"""
UniDataHub - Crawl4AI University Scraper
=========================================
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–∞–π—Ç–æ–≤ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–æ–≤ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–∞.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
- Crawl4AI (–±—Ä–∞—É–∑–µ—Ä–Ω–∞—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è)
- Google Gemini 1.5 Flash (—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö)
- Pydantic (–≤–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ö–µ–º—ã)

–õ–æ–≥–∏–∫–∞:
1. –ó–∞—Ö–æ–¥–∏—Ç –Ω–∞ –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É -> –ò—â–µ—Ç —Å—Å—ã–ª–∫–∏ (About, Programs, Admissions).
2. –ü–∞—Ä—Å–∏—Ç –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É.
3. (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –ü–∞—Ä—Å–∏—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã.
4. –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –µ–¥–∏–Ω—ã–π JSON.
"""

import os
import json
import asyncio
import logging
import re
import hashlib
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Dict, Any, Set, Tuple

# ---------------------------------------------------------
# –ò–ú–ü–û–†–¢–´ –ò –ù–ê–°–¢–†–û–ô–ö–ê –û–ö–†–£–ñ–ï–ù–ò–Ø
# ---------------------------------------------------------

try:
    from dotenv import load_dotenv
    load_dotenv()  # –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–∑ .env —Ñ–∞–π–ª–∞
except ImportError:
    pass

from pydantic import BaseModel, Field

try:
    from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, LLMConfig, CacheMode
    from crawl4ai.extraction_strategy import LLMExtractionStrategy
except ImportError:
    print("‚ùå –û—à–∏–±–∫–∞: Crawl4AI –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
    print("–í—ã–ø–æ–ª–Ω–∏—Ç–µ: pip install crawl4ai[all]")
    print("–í—ã–ø–æ–ª–Ω–∏—Ç–µ: pip install crawl4ai[all]")
    exit(1)

try:
    from bs4 import BeautifulSoup
except ImportError:
    BeautifulSoup = None

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('crawl4ai.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ---------------------------------------------------------
# 1. –°–•–ï–ú–ê –î–ê–ù–ù–´–• (PYDANTIC)
# ---------------------------------------------------------

class AboutUniversity(BaseModel):
    mission: Optional[str] = Field(None, description="–ú–∏—Å—Å–∏—è —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞.")
    history_summary: Optional[str] = Field(None, description="–ö—Ä–∞—Ç–∫–∞—è –∏—Å—Ç–æ—Ä–∏—è (–≥–æ–¥ –æ—Å–Ω–æ–≤–∞–Ω–∏—è, –≤–∞–∂–Ω—ã–µ —Ñ–∞–∫—Ç—ã).")
    leadership: Optional[str] = Field(None, description="–ò–º—è —Ä–µ–∫—Ç–æ—Ä–∞.")
    achievements: List[str] = Field(default_factory=list, description="–°–ø–∏—Å–æ–∫ –Ω–∞–≥—Ä–∞–¥, –º–µ—Å—Ç–∞ –≤ —Ä–µ–π—Ç–∏–Ω–≥–∞—Ö (QS, THE).")

class AcademicProgram(BaseModel):
    program_name: str = Field(..., description="–ù–∞–∑–≤–∞–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏/–ø—Ä–æ–≥—Ä–∞–º–º—ã.")
    degree_level: str = Field(..., description="–£—Ä–æ–≤–µ–Ω—å (–ë–∞–∫–∞–ª–∞–≤—Ä–∏–∞—Ç, –ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞, PhD).")
    faculty: Optional[str] = Field(None, description="–§–∞–∫—É–ª—å—Ç–µ—Ç –∏–ª–∏ —à–∫–æ–ª–∞.")

class Admissions(BaseModel):
    requirements: Optional[str] = Field(None, description="–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è (–ï–ù–¢, –ø—Ä–æ—Ö–æ–¥–Ω—ã–µ –±–∞–ª–ª—ã).")
    deadlines: Optional[str] = Field(None, description="–î–∞—Ç—ã –ø—Ä–∏–µ–º–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")
    scholarships: Optional[str] = Field(None, description="–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≥—Ä–∞–Ω—Ç–∞—Ö –∏ —Å–∫–∏–¥–∫–∞—Ö.")
    tuition_info: Optional[str] = Field(None, description="–°—Ç–æ–∏–º–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å).")

class VirtualTour(BaseModel):
    is_available: bool = Field(False, description="–ï—Å—Ç—å –ª–∏ 3D —Ç—É—Ä.")
    url: Optional[str] = Field(None, description="–°—Å—ã–ª–∫–∞ –Ω–∞ 3D —Ç—É—Ä.")

class InternationalCooperation(BaseModel):
    partners: List[str] = Field(default_factory=list, description="–í–£–ó—ã-–ø–∞—Ä—Ç–Ω–µ—Ä—ã.")
    exchange_programs: Optional[str] = Field(None, description="–ü—Ä–æ–≥—Ä–∞–º–º—ã –æ–±–º–µ–Ω–∞ (Erasmus –∏ –¥—Ä).")

class UniversityStats(BaseModel):
    employment_rate: Optional[str] = Field(None, description="–ü—Ä–æ—Ü–µ–Ω—Ç —Ç—Ä—É–¥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (—Å—Ç—Ä–æ–∫–æ–π, –Ω–∞–ø—Ä–∏–º–µ—Ä '95%').")
    student_count: Optional[str] = Field(None, description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤.")

class UniversityData(BaseModel):
    """–û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã—Ö —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞."""
    university_name: str = Field(..., description="–ù–∞–∑–≤–∞–Ω–∏–µ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞.")
    city: Optional[str] = Field(None, description="–ì–æ—Ä–æ–¥.")
    website: Optional[str] = Field(None, description="URL —Å–∞–π—Ç–∞.")
    about: AboutUniversity = Field(default_factory=AboutUniversity)
    academic_programs: List[AcademicProgram] = Field(default_factory=list)
    admissions: Admissions = Field(default_factory=Admissions)
    virtual_tour: VirtualTour = Field(default_factory=VirtualTour)
    international: InternationalCooperation = Field(default_factory=InternationalCooperation)
    stats: UniversityStats = Field(default_factory=UniversityStats)

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Å—ã–ª–æ–∫
class LinkOfInterest(BaseModel):
    url: str = Field(..., description="–ü–æ–ª–Ω–∞—è —Å—Å—ã–ª–∫–∞.")
    section_type: str = Field(..., description="–¢–∏–ø: 'about', 'programs', 'admissions', 'international'.")
    title: str = Field(..., description="–¢–µ–∫—Å—Ç —Å—Å—ã–ª–∫–∏.")

class LinksDiscovery(BaseModel):
    links: List[LinkOfInterest] = Field(default_factory=list)

# ---------------------------------------------------------
# 2. –î–ê–ù–ù–´–ï (–°–ü–ò–°–û–ö –£–ù–ò–í–ï–†–°–ò–¢–ï–¢–û–í)
# ---------------------------------------------------------
# –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ URL (–±–µ–∑ Markdown —Ä–∞–∑–º–µ—Ç–∫–∏)
KAZAKHSTAN_UNIVERSITIES = [

# ============================================================

# –ù–ê–¶–ò–û–ù–ê–õ–¨–ù–´–ï –£–ù–ò–í–ï–†–°–ò–¢–ï–¢–´ (11)

# ============================================================

{'name': '–ù–∞–∑–∞—Ä–±–∞–µ–≤ –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://nu.edu.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},

{'name': '–ö–∞–∑–∞—Ö—Å–∫–∏–π –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –∞–ª—å-–§–∞—Ä–∞–±–∏', 'url': 'https://kaznu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ï–≤—Ä–∞–∑–∏–π—Å–∫–∏–π –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –õ.–ù. –ì—É–º–∏–ª—ë–≤–∞', 'url': 'https://enu.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},

{'name': 'Satbayev University (–ö–∞–∑–ù–ò–¢–£)', 'url': 'https://satbayev.university', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ö–∞–∑–∞—Ö—Å–∫–∏–π –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ–¥–∞–≥–æ–≥–∏—á–µ—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –ê–±–∞—è', 'url': 'https://kaznpu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ö–∞–∑–∞—Ö—Å–∫–∏–π –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–≥—Ä–∞—Ä–Ω—ã–π –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://kaznau.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ö–∞–∑–∞—Ö—Å–∫–∏–π –∞–≥—Ä–æ—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –°. –°–µ–π—Ñ—É–ª–ª–∏–Ω–∞', 'url': 'https://kazatu.edu.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},

{'name': '–ö–∞–∑–∞—Ö—Å–∫–∏–π –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –°.–î. –ê—Å—Ñ–µ–Ω–¥–∏—è—Ä–æ–≤–∞', 'url': 'https://kaznmu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ö–∞–∑–∞—Ö—Å–∫–∞—è –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–æ—Ä–∏—è –∏–º. –ö—É—Ä–º–∞–Ω–≥–∞–∑—ã', 'url': 'https://conservatoire.edu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ö–∞–∑–∞—Ö—Å–∫–∞—è –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –∞–∫–∞–¥–µ–º–∏—è –∏—Å–∫—É—Å—Å—Ç–≤ –∏–º. –¢.–ö. –ñ—É—Ä–≥–µ–Ω–æ–≤–∞', 'url': 'https://kaznai.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ö–∞–∑–∞—Ö—Å–∫–∏–π –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∂–µ–Ω—Å–∫–∏–π –ø–µ–¥–∞–≥–æ–≥–∏—á–µ—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://kazmkpu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},


# ============================================================

# –ú–ï–ñ–î–£–ù–ê–†–û–î–ù–´–ï –£–ù–ò–í–ï–†–°–ò–¢–ï–¢–´ (5)

# ============================================================

{'name': '–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–æ-–ë—Ä–∏—Ç–∞–Ω—Å–∫–∏–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://kbtu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': 'KIMEP University', 'url': 'https://kimep.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–π –∫–∞–∑–∞—Ö—Å–∫–æ-—Ç—É—Ä–µ—Ü–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –•.–ê. –Ø—Å–∞–≤–∏', 'url': 'https://ayu.edu.kz', 'city': '–¢—É—Ä–∫–µ—Å—Ç–∞–Ω'},

{'name': '–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–æ-–ù–µ–º–µ—Ü–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://dku.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ö–∞–∑–∞—Ö—Å–∫–æ-–†–æ—Å—Å–∏–π—Å–∫–∏–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://krmu.edu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},


# ============================================================

# –ì–û–°–£–î–ê–†–°–¢–í–ï–ù–ù–´–ï –†–ï–ì–ò–û–ù–ê–õ–¨–ù–´–ï –£–ù–ò–í–ï–†–°–ò–¢–ï–¢–´ (25)

# ============================================================

{'name': '–Æ–∂–Ω–æ-–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –ú. –ê—É—ç–∑–æ–≤–∞', 'url': 'https://auezov.edu.kz', 'city': '–®—ã–º–∫–µ–Ω—Ç'},

{'name': '–ö–∞—Ä–∞–≥–∞–Ω–¥–∏–Ω—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –ï.–ê. –ë—É–∫–µ—Ç–æ–≤–∞', 'url': 'https://buketov.edu.kz', 'city': '–ö–∞—Ä–∞–≥–∞–Ω–¥–∞'},

{'name': '–ö–∞—Ä–∞–≥–∞–Ω–¥–∏–Ω—Å–∫–∏–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –ê. –°–∞–≥–∏–Ω–æ–≤–∞', 'url': 'https://ktu.edu.kz', 'city': '–ö–∞—Ä–∞–≥–∞–Ω–¥–∞'},

{'name': '–¢–æ—Ä–∞–π–≥—ã—Ä–æ–≤ –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://tou.edu.kz', 'city': '–ü–∞–≤–ª–æ–¥–∞—Ä'},

{'name': '–ö—ã–∑—ã–ª–æ—Ä–¥–∏–Ω—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –ö–æ—Ä–∫—ã—Ç –ê—Ç–∞', 'url': 'https://korkyt.kz', 'city': '–ö—ã–∑—ã–ª–æ—Ä–¥–∞'},

{'name': '–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –®–∞–∫–∞—Ä–∏–º–∞', 'url': 'https://semgu.kz', 'city': '–°–µ–º–µ–π'},

{'name': '–í–æ—Å—Ç–æ—á–Ω–æ-–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–∏–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –î. –°–µ—Ä–∏–∫–±–∞–µ–≤–∞', 'url': 'https://ektu.kz', 'city': '–£—Å—Ç—å-–ö–∞–º–µ–Ω–æ–≥–æ—Ä—Å–∫'},

{'name': '–í–æ—Å—Ç–æ—á–Ω–æ-–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –°. –ê–º–∞–Ω–∂–æ–ª–æ–≤–∞', 'url': 'https://vku.edu.kz', 'city': '–£—Å—Ç—å-–ö–∞–º–µ–Ω–æ–≥–æ—Ä—Å–∫'},

{'name': '–°–µ–≤–µ—Ä–æ-–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –ú. –ö–æ–∑—ã–±–∞–µ–≤–∞', 'url': 'https://nku.edu.kz', 'city': '–ü–µ—Ç—Ä–æ–ø–∞–≤–ª–æ–≤—Å–∫'},

{'name': '–ê–∫—Ç—é–±–∏–Ω—Å–∫–∏–π —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –ö. –ñ—É–±–∞–Ω–æ–≤–∞', 'url': 'https://arsu.kz', 'city': '–ê–∫—Ç–æ–±–µ'},

{'name': '–ê—Ç—ã—Ä–∞—É—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –•. –î–æ—Å–º—É—Ö–∞–º–µ–¥–æ–≤–∞', 'url': 'https://asu.edu.kz', 'city': '–ê—Ç—ã—Ä–∞—É'},

{'name': '–ê—Ç—ã—Ä–∞—É—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –Ω–µ—Ñ—Ç–∏ –∏ –≥–∞–∑–∞ –∏–º. –°. –£—Ç–µ–±–∞–µ–≤–∞', 'url': 'https://aogu.edu.kz', 'city': '–ê—Ç—ã—Ä–∞—É'},

{'name': '–ó–∞–ø–∞–¥–Ω–æ-–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –ú. –£—Ç–µ–º–∏—Å–æ–≤–∞', 'url': 'https://wksu.kz', 'city': '–£—Ä–∞–ª—å—Å–∫'},

{'name': '–ó–∞–ø–∞–¥–Ω–æ-–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–∏–π –∞–≥—Ä–∞—Ä–Ω–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –ñ–∞–Ω–≥–∏—Ä —Ö–∞–Ω–∞', 'url': 'https://wkau.kz', 'city': '–£—Ä–∞–ª—å—Å–∫'},

{'name': '–ñ–µ—Ç—ã—Å—É—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –ò. –ñ–∞–Ω—Å—É–≥—É—Ä–æ–≤–∞', 'url': 'https://zhgu.edu.kz', 'city': '–¢–∞–ª–¥—ã–∫–æ—Ä–≥–∞–Ω'},

{'name': '–¢–∞—Ä–∞–∑—Å–∫–∏–π —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –ú.–•. –î—É–ª–∞—Ç–∏', 'url': 'https://tarsu.kz', 'city': '–¢–∞—Ä–∞–∑'},

{'name': '–ö–æ—Å—Ç–∞–Ω–∞–π—Å–∫–∏–π —Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –ê. –ë–∞–π—Ç—É—Ä—Å—ã–Ω–æ–≤–∞', 'url': 'https://ksu.edu.kz', 'city': '–ö–æ—Å—Ç–∞–Ω–∞–π'},

{'name': '–ö–æ–∫—à–µ—Ç–∞—É—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –®. –£–∞–ª–∏—Ö–∞–Ω–æ–≤–∞', 'url': 'https://kgu.kz', 'city': '–ö–æ–∫—à–µ—Ç–∞—É'},

{'name': '–ú–∞–Ω–≥–∏—Å—Ç–∞—É—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –®. –ï—Å–µ–Ω–æ–≤–∞', 'url': 'https://mu.edu.kz', 'city': '–ê–∫—Ç–∞—É'},

{'name': '–ê—Ä–∫–∞–ª—ã–∫—Å–∫–∏–π –ø–µ–¥–∞–≥–æ–≥–∏—á–µ—Å–∫–∏–π –∏–Ω—Å—Ç–∏—Ç—É—Ç –∏–º. –ò. –ê–ª—Ç—ã–Ω—Å–∞—Ä–∏–Ω–∞', 'url': 'https://api.kz', 'city': '–ê—Ä–∫–∞–ª—ã–∫'},

{'name': '–ö–∞—Ä–∞–≥–∞–Ω–¥–∏–Ω—Å–∫–∏–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://kgmu.kz', 'city': '–ö–∞—Ä–∞–≥–∞–Ω–¥–∞'},

{'name': '–ó–∞–ø–∞–¥–Ω–æ-–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–∏–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –ú. –û—Å–ø–∞–Ω–æ–≤–∞', 'url': 'https://zkmu.kz', 'city': '–ê–∫—Ç–æ–±–µ'},

{'name': '–°–µ–º–µ–π—Å–∫–∏–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://semeymeduniversity.kz', 'city': '–°–µ–º–µ–π'},

{'name': '–Æ–∂–Ω–æ-–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–∞—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –∞–∫–∞–¥–µ–º–∏—è', 'url': 'https://ukma.kz', 'city': '–®—ã–º–∫–µ–Ω—Ç'},

{'name': '–ê—Å—Ç–∞–Ω–∏–Ω—Å–∫–∏–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://amu.edu.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},


# ============================================================

# –ß–ê–°–¢–ù–´–ï –£–ù–ò–í–ï–†–°–ò–¢–ï–¢–´ - –ê–õ–ú–ê–¢–´ (30)

# ============================================================

{'name': 'SDU University', 'url': 'https://sdu.edu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': 'Almaty Management University (AlmaU)', 'url': 'https://almau.edu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': 'International IT University (IITU)', 'url': 'https://iitu.edu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–≥–æ –±–∏–∑–Ω–µ—Å–∞ (UIB)', 'url': 'https://uib.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –¢—É—Ä–∞–Ω', 'url': 'https://turan-edu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': 'Narxoz University', 'url': 'https://narxoz.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ê–ª–º–∞—Ç–∏–Ω—Å–∫–∏–π —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://atu.edu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ê–ª–º–∞—Ç–∏–Ω—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∏ –∏ —Å–≤—è–∑–∏ –∏–º. –ì. –î–∞—É–∫–µ–µ–≤–∞', 'url': 'https://aues.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ö–∞–∑–∞—Ö—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ –±–∏–∑–Ω–µ—Å–∞', 'url': 'https://kutb.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},

{'name': '–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –ù–∞—Ä—Ö–æ–∑', 'url': 'https://narxoz.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ê–ª–º–∞—Ç—ã –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://almau.edu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–∏–π –∏–Ω–∂–µ–Ω–µ—Ä–Ω–æ-—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://kitu.edu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ê–ª–º–∞—Ç–∏–Ω—Å–∫–∏–π –≥—É–º–∞–Ω–∏—Ç–∞—Ä–Ω–æ-—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://algeu.edu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ö–∞—Å–ø–∏–π—Å–∫–∏–π –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –∏ –∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥–∞ –∏–º. –®. –ï—Å–µ–Ω–æ–≤–∞', 'url': 'https://kguti.kz', 'city': '–ê–∫—Ç–∞—É'},

{'name': '–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ-–ê–∑–∏–∞—Ç—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://cau.edu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –ê–ª–º–∞—Ç—ã', 'url': 'https://almaty-uni.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ö–∞–∑–∞—Ö—Å–∫–∏–π –≥—É–º–∞–Ω–∏—Ç–∞—Ä–Ω–æ-—é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://kgyu.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},

{'name': 'M. Narikbayev University (KAZGUU)', 'url': 'https://kazguu.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},

{'name': '–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –ö–∞–∑–ì–Æ–ò–£', 'url': 'https://kazguu.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},

{'name': '–ï–≤—Ä–∞–∑–∏–π—Å–∫–∏–π —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://etu.edu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ê–∫–∞–¥–µ–º–∏—è –ö–∞–π–Ω–∞—Ä', 'url': 'https://kainar-edu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ê–ª–º–∞—Ç–∏–Ω—Å–∫–∞—è –∞–∫–∞–¥–µ–º–∏—è —ç–∫–æ–Ω–æ–º–∏–∫–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏', 'url': 'https://aesa.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –ú–∏—Ä–∞—Å', 'url': 'https://miras.edu.kz', 'city': '–®—ã–º–∫–µ–Ω—Ç'},

{'name': '–ö–∞–∑–∞—Ö—Å–∫–∞—è –∞–∫–∞–¥–µ–º–∏—è —Ç—Ä—É–¥–∞ –∏ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π', 'url': 'https://atso.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∏ —Ç–µ–ª–µ–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º', 'url': 'https://kazkits.kz', 'city': '–£—Ä–∞–ª—å—Å–∫'},

{'name': '–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –°—ã—Ä–¥–∞—Ä–∏—è', 'url': 'https://syrdariya.kz', 'city': '–ñ–µ—Ç—ã—Å–∞–π'},

{'name': '–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ-–ê–∑–∏–∞—Ç—Å–∫–∏–π –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://caiu.edu.kz', 'city': '–®—ã–º–∫–µ–Ω—Ç'},

{'name': '–ò–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã–π –ï–≤—Ä–∞–∑–∏–π—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://ieu.edu.kz', 'city': '–ü–∞–≤–ª–æ–¥–∞—Ä'},

{'name': '–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –£–ª–∞–≥–∞—Ç', 'url': 'https://ulagat.edu.kz', 'city': '–ö—ã–∑—ã–ª–æ—Ä–¥–∞'},

{'name': '–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –ë–æ–ª–∞—à–∞–∫', 'url': 'https://bulan.edu.kz', 'city': '–ö–∞—Ä–∞–≥–∞–Ω–¥–∞'},


# ============================================================

# –ß–ê–°–¢–ù–´–ï –£–ù–ò–í–ï–†–°–ò–¢–ï–¢–´ - –ê–°–¢–ê–ù–ê (15)

# ============================================================

{'name': 'Astana IT University', 'url': 'https://astanait.edu.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},

{'name': '–ï–≤—Ä–∞–∑–∏–π—Å–∫–∏–π –≥—É–º–∞–Ω–∏—Ç–∞—Ä–Ω—ã–π –∏–Ω—Å—Ç–∏—Ç—É—Ç', 'url': 'https://egi.edu.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},

{'name': '–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –¢—É—Ä–∞–Ω-–ê—Å—Ç–∞–Ω–∞', 'url': 'https://turan-astana.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},

{'name': '–ö–∞–∑–∞—Ö—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç —ç–∫–æ–Ω–æ–º–∏–∫–∏, —Ñ–∏–Ω–∞–Ω—Å–æ–≤ –∏ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–∏', 'url': 'https://kuef.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},

{'name': '–ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –ê—Å—Ç–∞–Ω–∞', 'url': 'https://mua.edu.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},

{'name': '–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –ï—Å–µ–Ω–æ–≤–∞', 'url': 'https://essenov.edu.kz', 'city': '–ê–∫—Ç–∞—É'},

{'name': '–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç ADAM', 'url': 'https://adam.edu.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},

{'name': '–ï–≤—Ä–∞–∑–∏–π—Å–∫–∞—è —é—Ä–∏–¥–∏—á–µ—Å–∫–∞—è –∞–∫–∞–¥–µ–º–∏—è –∏–º. –î.–ê. –ö—É–Ω–∞–µ–≤–∞', 'url': 'https://eyau.edu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –Ω–∞—Ä–æ–¥–Ω–æ–≥–æ –¥—Ä—É–∂–±—ã', 'url': 'https://kudn.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},

{'name': '–ê–∫–∞–¥–µ–º–∏—è –ª–æ–≥–∏—Å—Ç–∏–∫–∏ –∏ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞', 'url': 'https://alt.edu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ê–∫–∞–¥–µ–º–∏—è –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–π –∞–≤–∏–∞—Ü–∏–∏', 'url': 'https://aca.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ö–∞–∑–∞—Ö—Å–∫–∞—è –∞–∫–∞–¥–µ–º–∏—è —Å–ø–æ—Ä—Ç–∞ –∏ —Ç—É—Ä–∏–∑–º–∞', 'url': 'https://kazast.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ê–ª–∏—Ö–∞–Ω –ë–æ–∫–µ–π—Ö–∞–Ω —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://abu.edu.kz', 'city': '–°–µ–º–µ–π'},

{'name': '–ë–∞–∏—à–µ–≤ –£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://baishev.edu.kz', 'city': '–ê–∫—Ç–æ–±–µ'},

{'name': '–ê–∫–∞–¥–µ–º–∏—è Bolashaq', 'url': 'https://bolashaq.edu.kz', 'city': '–ö–∞—Ä–∞–≥–∞–Ω–¥–∞'},


# ============================================================

# –°–ü–ï–¶–ò–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ï –í–£–ó–´ (12)

# ============================================================

{'name': '–ö–∞–∑–∞—Ö—Å–∫–∞—è –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –∞–∫–∞–¥–µ–º–∏—è —Ö–æ—Ä–µ–æ–≥—Ä–∞—Ñ–∏–∏', 'url': 'https://balletacademy.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},

{'name': '–ö–∞–∑–∞—Ö—Å–∫–∏–π –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏—Å–∫—É—Å—Å—Ç–≤', 'url': 'https://kaznui.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},

{'name': '–ö–∞–∑–∞—Ö—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π –∏ –º–∏—Ä–æ–≤—ã—Ö —è–∑—ã–∫–æ–≤ –∏–º. –ê–±—ã–ª–∞–π —Ö–∞–Ω–∞', 'url': 'https://ablaikhan.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ö–∞–∑–∞—Ö—Å–∫–∞—è –∞–∫–∞–¥–µ–º–∏—è —Ñ–∏–∑–∏—á–µ—Å–∫–æ–π –∫—É–ª—å—Ç—É—Ä—ã –∏ —Å–ø–æ—Ä—Ç–∞', 'url': 'https://kazafc.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–í–æ–µ–Ω–Ω—ã–π –∏–Ω—Å—Ç–∏—Ç—É—Ç –°—É—Ö–æ–ø—É—Ç–Ω—ã—Ö –≤–æ–π—Å–∫', 'url': 'https://visu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –æ–±–æ—Ä–æ–Ω—ã –∏–º. –ü–µ—Ä–≤–æ–≥–æ –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –†–ö', 'url': 'https://nuo.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},

{'name': '–ê–∫–∞–¥–µ–º–∏—è –ø—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –æ—Ä–≥–∞–Ω–æ–≤ –ø—Ä–∏ –ì–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–π –ø—Ä–æ–∫—É—Ä–∞—Ç—É—Ä–µ', 'url': 'https://apo.gov.kz', 'city': '–ê—Å—Ç–∞–Ω–∞'},

{'name': '–ü–æ–≥—Ä–∞–Ω–∏—á–Ω–∞—è –∞–∫–∞–¥–µ–º–∏—è –ö–ù–ë –†–ö', 'url': 'https://pa.gov.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ê–ª–º–∞—Ç–∏–Ω—Å–∫–∞—è –∞–∫–∞–¥–µ–º–∏—è –ú–í–î –†–ö', 'url': 'https://amvd.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ö–æ—Å—Ç–∞–Ω–∞–π—Å–∫–∞—è –∞–∫–∞–¥–µ–º–∏—è –ú–í–î –†–ö', 'url': 'https://kamvd.kz', 'city': '–ö–æ—Å—Ç–∞–Ω–∞–π'},

{'name': '–ö–∞—Ä–∞–≥–∞–Ω–¥–∏–Ω—Å–∫–∞—è –∞–∫–∞–¥–µ–º–∏—è –ú–í–î –†–ö', 'url': 'https://karaganda.mvd.kz', 'city': '–ö–∞—Ä–∞–≥–∞–Ω–¥–∞'},

{'name': '–ê–∫—Ç—é–±–∏–Ω—Å–∫–∏–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π –∏–Ω—Å—Ç–∏—Ç—É—Ç –ú–í–î', 'url': 'https://aktyubmvd.kz', 'city': '–ê–∫—Ç–æ–±–µ'},


# ============================================================

# –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –†–ï–ì–ò–û–ù–ê–õ–¨–ù–´–ï –í–£–ó–´ (15)

# ============================================================

{'name': '–ì—É–º–∞–Ω–∏—Ç–∞—Ä–Ω–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∞–∫–∞–¥–µ–º–∏—è', 'url': 'https://gta.edu.kz', 'city': '–ö–æ–∫—à–µ—Ç–∞—É'},

{'name': '–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –ï—Å–µ–Ω–æ–≤–∞', 'url': 'https://esenovuniversity.kz', 'city': '–ê–∫—Ç–∞—É'},

{'name': '–†—É–¥–Ω–µ–Ω—Å–∫–∏–π –∏–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã–π –∏–Ω—Å—Ç–∏—Ç—É—Ç', 'url': 'https://rii.kz', 'city': '–†—É–¥–Ω—ã–π'},

{'name': '–ñ–µ–∑–∫–∞–∑–≥–∞–Ω—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –∏–º. –û. –ë–∞–π–∫–æ–Ω—É—Ä–æ–≤–∞', 'url': 'https://zhezu.kz', 'city': '–ñ–µ–∑–∫–∞–∑–≥–∞–Ω'},

{'name': '–ê—Ç—ã—Ä–∞—É—Å–∫–∏–π –∏–Ω–∂–µ–Ω–µ—Ä–Ω–æ-–≥—É–º–∞–Ω–∏—Ç–∞—Ä–Ω—ã–π –∏–Ω—Å—Ç–∏—Ç—É—Ç', 'url': 'https://aigi.kz', 'city': '–ê—Ç—ã—Ä–∞—É'},

{'name': '–®—ã–º–∫–µ–Ω—Ç—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://shimkent-uni.kz', 'city': '–®—ã–º–∫–µ–Ω—Ç'},

{'name': '–Æ–∂–Ω–æ-–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–∏–π –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–µ–¥–∞–≥–æ–≥–∏—á–µ—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://okmpu.kz', 'city': '–®—ã–º–∫–µ–Ω—Ç'},

{'name': '–ö–∞–∑–∞—Ö—Å–∫–∏–π –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://kazniu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –ö—É–Ω–∞–µ–≤–∞', 'url': 'https://kunaev-uni.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω—Å–∫–æ-–ê–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–π —Å–≤–æ–±–æ–¥–Ω—ã–π —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', 'url': 'https://kafu.kz', 'city': '–£—Å—Ç—å-–ö–∞–º–µ–Ω–æ–≥–æ—Ä—Å–∫'},

{'name': '–í—ã—Å—à–∞—è —à–∫–æ–ª–∞ –ø—Ä–∞–≤–∞ ”ò–¥—ñ–ª–µ—Ç', 'url': 'https://adilet.edu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–£–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç –°–∞–Ω–∞—Ç', 'url': 'https://sanat.edu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ê–∫–∞–¥–µ–º–∏—è –•–∞–ª—ã“õ–∞—Ä–∞–ª—ã“õ', 'url': 'https://halyk.edu.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': '–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∞—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –∫–æ—Ä–ø–æ—Ä–∞—Ü–∏—è (–ú–û–ö)', 'url': 'https://mok.kz', 'city': '–ê–ª–º–∞—Ç—ã'},

{'name': 'Pavlodar University', 'url': 'https://pvl.edu.kz', 'city': '–ü–∞–≤–ª–æ–¥–∞—Ä'},

]

# ---------------------------------------------------------
# 3. –ü–†–û–ú–ü–¢–´ –î–õ–Ø LLM
# ---------------------------------------------------------

EXTRACTION_INSTRUCTION = """
–†–û–õ–¨: Senior Data Extraction Analyst (—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç—ã/–∫–∞—Ç–∞–ª–æ–≥–∏).
–¶–ï–õ–¨: –ó–∞–ø–æ–ª–Ω–∏—Ç—å –æ–±—ä–µ–∫—Ç —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞ –¥–ª—è universities.ts —Å—Ç—Ä–æ–≥–æ –ø–æ —Å—Ö–µ–º–µ –Ω–∏–∂–µ, –∏—Å–ø–æ–ª—å–∑—É—è –¢–û–õ–¨–ö–û –¥–∞–Ω–Ω—ã–µ, –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –Ω–∞ —Å–∞–π—Ç–µ/—Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞.

–û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø:
- –Ø–∑—ã–∫ –≤—ã–≤–æ–¥–∞: –†–£–°–°–ö–ò–ô (–∏–º—è/shortName –¥–æ–ø—É—Å–∫–∞—é—Ç—Å—è –∫–∞–∫ –Ω–∞ —Å–∞–π—Ç–µ, –≤–∫–ª—é—á–∞—è –∫–∞–∑–∞—Ö—Å–∫–∏–π).
- –ù–ï –≤—ã–¥—É–º—ã–≤–∞—Ç—å –∏ –ù–ï –¥–æ–ø–æ–ª–Ω—è—Ç—å –∑–Ω–∞–Ω–∏—è–º–∏ ‚Äú–∏–∑ –≥–æ–ª–æ–≤—ã‚Äù.
- –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç: —Å—Ç–∞–≤—å 0 –¥–ª—è —á–∏—Å–µ–ª, "" –¥–ª—è —Å—Ç—Ä–æ–∫, [] –¥–ª—è –º–∞—Å—Å–∏–≤–æ–≤.
- –ù–µ –∫–æ–ø–∏—Ä—É–π –æ–≥—Ä–æ–º–Ω—ã–µ –ø—Ä–æ—Å—Ç—ã–Ω–∏. –í description –¥–µ–ª–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ –∏ –ø–æ –¥–µ–ª—É.
- –í—Å–µ —Å—Å—ã–ª–∫–∏ –≤–Ω—É—Ç—Ä–∏ description/–ø–æ–ª–µ–π —É–∫–∞–∑—ã–≤–∞–π —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∏ —Ä–µ–∞–ª—å–Ω–æ –µ—Å—Ç—å –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ.

–í–•–û–î:
1) university_base = { "website": "{{BASE_URL}}", "name_hint": "{{NAME_HINT}}", "id": "{{ID_HINT}}" }
2) page_content = "{{HTML_OR_TEXT_FROM_PAGES}}"   (–º–æ–∂–µ—Ç –≤–∫–ª—é—á–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü: –≥–ª–∞–≤–Ω–∞—è + about + admissions + programs + international + 3d tour)

–ó–ê–î–ê–ß–ò –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø:
1) about/—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ/–¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è -> –≤ –ø–æ–ª–µ description (—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–æ).
2) –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–µ -> admissions.deadline / admissions.requirements / admissions.scholarships
3) international -> international.partners (–∫–æ–ª-–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤) + international.exchangePrograms (–Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º –æ–±–º–µ–Ω–∞)
4) programs -> –º–∏–Ω–∏–º—É–º 5‚Äì15 –ø—Ä–æ–≥—Ä–∞–º–º (–µ—Å–ª–∏ –µ—Å—Ç—å), –∏–Ω–∞—á–µ —Å–∫–æ–ª—å–∫–æ –Ω–∞–π–¥–µ–Ω–æ
5) foundedYear -> –≥–æ–¥ –æ—Å–Ω–æ–≤–∞–Ω–∏—è (–µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî 0)
6) studentCount -> –µ—Å–ª–∏ –µ—Å—Ç—å —á–∏—Å–ª–æ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (–∏–Ω–∞—á–µ 0)
7) ranking -> –µ—Å–ª–∏ —Ä–µ–∞–ª—å–Ω–æ –µ—Å—Ç—å ‚Äú#1‚Äù/–º–µ—Å—Ç–æ –≤ —Ä–µ–π—Ç–∏–Ω–≥–µ –Ω–∞ —Å–∞–π—Ç–µ; –∏–Ω–∞—á–µ 0
8) virtual tour -> –µ—Å–ª–∏ –µ—Å—Ç—å, –¥–æ–±–∞–≤—å –≤ description —Å—Ç—Ä–æ–∫—É ‚Äú3D-—Ç—É—Ä: <url>‚Äù (–æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π)

–§–û–†–ú–ê–¢ –í–´–í–û–î–ê:
–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON –û–î–ù–û–ì–û –æ–±—ä–µ–∫—Ç–∞ (–±–µ–∑ markdown, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π), —Å—Ç—Ä–æ–≥–æ –ø–æ —ç—Ç–æ–π —Å—Ö–µ–º–µ:

{
  "id": "uni--{{stable_id_or_given}}",
  "name": "{{official_name}}",
  "shortName": "{{abbr_or_short}}",
  "location": "{{city_or_main_location}}",
  "description": "–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ: ...\n\n–î–æ—Å—Ç–∏–∂–µ–Ω–∏—è: ...\n\n–ü–æ—Å—Ç—É–ø–ª–µ–Ω–∏–µ (—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è): ...\n\n–°—Ä–æ–∫–∏ –ø—Ä–∏—ë–º–∞: ...\n\n–ì—Ä–∞–Ω—Ç—ã/—Å–∫–∏–¥–∫–∏/—Å—Ç–∏–ø–µ–Ω–¥–∏–∏: ...\n\n–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –ø–∞—Ä—Ç–Ω—ë—Ä—ã (–ø—Ä–∏–º–µ—Ä—ã): ...\n\n3D-—Ç—É—Ä: ...",
  "foundedYear": 0,
  "ranking": 0,
  "studentCount": 0,
  "acceptanceRate": 0,
  "tuitionRange": { "min": 0, "max": 0 },
  "website": "{{base_url}}",
  "logoUrl": "/logos/{{id}}.png",
  "imageUrl": "{{image_url_or_default}}",
  "type": "state|private",
  "programs": [
    {
      "id": "{{id}}-p-0",
      "name": "{{program_name}}",
      "degree": "Bachelor|Master|PhD|Foundation|Other",
      "duration": "{{e.g. '4 years' or ''}}",
      "tuition": 0,
      "language": "{{English|Russian|Kazakh|Other|''}}"
    }
  ],
  "admissions": {
    "deadline": [],
    "requirements": [],
    "scholarships": []
  },
  "international": {
    "partners": 0,
    "exchangePrograms": []
  },
  "stats": {
    "employmentRate": 0,
    "researchOutput": "Low|Medium|High",
    "studentSatisfaction": 0
  }
}

–ü–†–ê–í–ò–õ–ê –î–õ–Ø description:
- –î–µ–ª–∞–π —Ä–æ–≤–Ω–æ 6‚Äì8 –±–ª–æ–∫–æ–≤ –∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–µ (–∫–∞–∂–¥—ã–π —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º –∏ –¥–≤–æ–µ—Ç–æ—á–∏–µ–º).
- –í –∫–∞–∂–¥–æ–º –±–ª–æ–∫–µ 1‚Äì3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –º–∞–∫—Å–∏–º—É–º.
- –ï—Å–ª–∏ –±–ª–æ–∫–æ–≤ –Ω–µ—Ç ‚Äî –æ—Å—Ç–∞–≤–ª—è–π –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É "" –∏–ª–∏ –∑–∞–ø–æ–ª–Ω—è–π —Ç–æ–ª—å–∫–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –±–ª–æ–∫–∏.

–ü–†–ê–í–ò–õ–ê –î–õ–Ø programs:
- –ù–µ –¥–æ–±–∞–≤–ª—è–π ‚ÄúUndergraduate Programs‚Äù –∫–∞–∫ –ø—Ä–æ–≥—Ä–∞–º–º—É, –µ—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ —Ä–∞–∑–¥–µ–ª.
- –ï—Å–ª–∏ –Ω–µ—Ç —Å–ø–∏—Å–∫–∞ –ø—Ä–æ–≥—Ä–∞–º–º ‚Äî –≤–µ—Ä–Ω–∏ [].

–ü–†–û–í–ï–†–ö–ê –ü–ï–†–ï–î –û–¢–í–ï–¢–û–ú:
- JSON –≤–∞–ª–∏–¥–Ω—ã–π.
- –í—Å–µ –∫–ª—é—á–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç.
- –ù–µ—Ç null (—Ç–æ–ª—å–∫–æ 0/""/[]).

"""


LINK_DISCOVERY_INSTRUCTION = """
–¢—ã ‚Äî –º–æ–¥—É–ª—å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Å—Å—ã–ª–æ–∫ (link discovery) –¥–ª—è —Å–∞–π—Ç–∞ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞.
–ù—É–∂–Ω–æ –Ω–∞–π—Ç–∏ URL –∫–ª—é—á–µ–≤—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤. –ò—â–∏ –≤: –º–µ–Ω—é, —Ñ—É—Ç–µ—Ä–µ, —Å–∞–π–¥–±–∞—Ä–µ, —Ö–ª–µ–±–Ω—ã—Ö –∫—Ä–æ—à–∫–∞—Ö –∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Å—ã–ª–∫–∞—Ö.

–í–µ—Ä–Ω–∏ –°–¢–†–û–ì–û JSON-–º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤:
[
  {
    "key": "about|programs|admissions|tour_3d|international",
    "url": "https://....",
    "anchor_text": "—Ç–µ–∫—Å—Ç —Å—Å—ã–ª–∫–∏ –∫–∞–∫ –Ω–∞ —Å–∞–π—Ç–µ",
    "confidence": 0.0-1.0
  }
]

–ö–ª—é—á–∏:
- about: –û –Ω–∞—Å / –û–± —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–µ / –ú–∏—Å—Å–∏—è / –ò—Å—Ç–æ—Ä–∏—è / –†–µ–∫—Ç–æ—Ä / –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ
- programs: –ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã / –°–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏ / –§–∞–∫—É–ª—å—Ç–µ—Ç—ã / –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ / Programs / Faculties
- admissions: –ü–æ—Å—Ç—É–ø–ª–µ–Ω–∏–µ / –ê–±–∏—Ç—É—Ä–∏–µ–Ω—Ç—É / –ü—Ä–∏–µ–º–Ω–∞—è –∫–æ–º–∏—Å—Å–∏—è / Admissions / Enrollment
- tour_3d: 3D-—Ç—É—Ä / –í–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π —Ç—É—Ä / Virtual tour / –ü–∞–Ω–æ—Ä–∞–º–∞
- international: –ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–µ —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–æ / International / Mobility / Partners / Erasmus

–ü—Ä–∞–≤–∏–ª–∞:
1) –í–æ–∑–≤—Ä–∞—â–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–µ –ü–û–õ–ù–´–ï URL (–∞–±—Å–æ–ª—é—Ç–Ω—ã–µ). –ï—Å–ª–∏ —Å—Å—ã–ª–∫–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑—É–π –≤ –∞–±—Å–æ–ª—é—Ç–Ω—É—é.
2) –£–±–µ—Ä–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã (–æ–¥–∏–Ω–∞–∫–æ–≤—ã–π URL).
3) –ù–µ –≤–∫–ª—é—á–∞–π —Å–æ—Ü—Å–µ—Ç–∏, PDF, —Ñ–∞–π–ª—ã, –Ω–æ–≤–æ—Å—Ç–∏ (–µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —Ä–∞–∑–¥–µ–ª–æ–º).
4) –ï—Å–ª–∏ —Ä–∞–∑–¥–µ–ª–∞ –Ω–µ—Ç ‚Äî –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–π –æ–±—ä–µ–∫—Ç —Å —ç—Ç–∏–º key.
5) –°–æ—Ä—Ç–∏—Ä—É–π –ø–æ confidence –ø–æ —É–±—ã–≤–∞–Ω–∏—é.

–ù–∏—á–µ–≥–æ –∫—Ä–æ–º–µ JSON –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–π.
"""


# ---------------------------------------------------------
# 4. –õ–û–ì–ò–ö–ê –ü–ê–†–°–ï–†–ê
# ---------------------------------------------------------

class UniversityScraper:
    def __init__(self, api_key: str, output_file: str = "universities_data.json"):
        self.api_key = api_key
        # –Ø–í–ù–û–ï –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï GEMINI FLASH LATEST (Corrected)
        self.provider = "gemini/gemini-flash-latest"
        self.output_file = output_file
        self.results = []
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        if os.path.exists(output_file):
            try:
                with open(output_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.results = data.get('universities', [])
            except Exception:
                pass

    def _get_llm_config(self) -> LLMConfig:
        return LLMConfig(provider=self.provider, api_token=self.api_key)

    def _clean_json(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç –æ—Ç–≤–µ—Ç LLM –æ—Ç Markdown –±–ª–æ–∫–æ–≤."""
        text = re.sub(r'^```json\s*', '', text, flags=re.MULTILINE)
        text = re.sub(r'^```\s*', '', text, flags=re.MULTILINE)
        return text.strip()

    async def discover_links(self, url: str, html: Optional[str] = None) -> List[Dict]:
        """–§–∞–∑–∞ 1: –ü–æ–∏—Å–∫ —Å—Å—ã–ª–æ–∫ (LLM + Fallback)."""
        logger.info(f"üîç Searching links for: {url}")
        
        # Optimization: If HTML is provided (from main scrape), skip network call!
        if html and BeautifulSoup:
            logger.info("‚ö°Ô∏è Using cached HTML for link discovery")
            return self._heuristic_link_discovery(html, url)

        # 1. –ü–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ LLM (Network Call)
        strategy = LLMExtractionStrategy(
            llm_config=self._get_llm_config(),
            schema=LinksDiscovery.model_json_schema(),
            instruction=LINK_DISCOVERY_INSTRUCTION
        )
        
        config = CrawlerRunConfig(
            extraction_strategy=strategy,
            cache_mode=CacheMode.BYPASS,
            page_timeout=40000,
            wait_until="domcontentloaded"
        )

        async with AsyncWebCrawler(config=BrowserConfig(headless=True, extra_args=["--disable-blink-features=AutomationControlled"], ignore_https_errors=True)) as crawler:
            try:
                # –ü–æ–ª—É—á–∞–µ–º –∏ HTML –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç LLM
                result = await crawler.arun(url=url, config=config)
                
                llm_links = []
                if result.success and result.extracted_content:
                    try:
                        clean_content = self._clean_json(result.extracted_content)
                        data = json.loads(clean_content)
                        if isinstance(data, list) and data:
                            data = data[0]
                        llm_links = data.get('links', [])
                    except Exception:
                        pass
                
                if llm_links:
                    return llm_links
                    
                # 2. Fallback: Heuristic
                logger.info("‚ö†Ô∏è LLM found 0 links, trying heuristic fallback...")
                if result.success and result.html and BeautifulSoup:
                    return self._heuristic_link_discovery(result.html, url)
                    
            except Exception as e:
                logger.error(f"Link discovery failed significantly: {e}")
        
        return []

    def _heuristic_link_discovery(self, html: str, base_url: str) -> List[Dict]:
        """–ü–æ–∏—Å–∫ —Å—Å—ã–ª–æ–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º —á–µ—Ä–µ–∑ BS4."""
        soup = BeautifulSoup(html, 'html.parser')
        links = []
        seen = set()
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ä–∞–∑–¥–µ–ª–æ–≤
        keywords = {
            'about': ['about', '–æ –Ω–∞—Å', '–∏—Å—Ç–æ—Ä–∏—è', 'history', 'mission', '–º–∏—Å—Å–∏—è'],
            'programs': ['program', '–ø—Ä–æ–≥—Ä–∞–º–º—ã', 'academics', '–æ–±—É—á–µ–Ω–∏–µ', 'specialties', '—Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏', 'degree', '–±–∞–∫–∞–ª–∞–≤—Ä–∏–∞—Ç'],
            'admissions': ['admission', '–ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–µ', '–∞–±–∏—Ç—É—Ä–∏–µ–Ω—Ç', 'apply', '–ø—Ä–∏–µ–º'],
            'international': ['international', '–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥', 'partner', 'global'],
            'virtual_tour': ['3d', 'tour', '—Ç—É—Ä', '–≤–∏—Ä—Ç—É–∞–ª—å–Ω']
        }
        
        from urllib.parse import urljoin

        for a in soup.find_all('a', href=True):
            text = a.get_text(strip=True).lower()
            href = a['href']
            full_url = urljoin(base_url, href)
            
            if not text or len(text) < 3: continue
            
            for section, keys in keywords.items():
                if any(k in text for k in keys) and full_url not in seen:
                    links.append({
                        "url": full_url,
                        "section_type": section,
                        "title": text[:50]
                    })
                    seen.add(full_url)
                    break # Assign to first matching category
                    
        return links[:15] # Return top matches

    async def scrape_page(self, url: str, schema_cls=UniversityData) -> Tuple[Optional[Dict], Optional[str]]:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (data, html)."""
        strategy = LLMExtractionStrategy(
            llm_config=self._get_llm_config(),
            schema=schema_cls.model_json_schema(),
            instruction=EXTRACTION_INSTRUCTION,
            magic=True
        )
        
        browser_cfg = BrowserConfig(
            browser_type="chromium",
            headless=True,
            ignore_https_errors=True,
            headers={
                # –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π User-Agent (Chrome –Ω–∞ macOS)
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
                "Accept-Language": "ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7",
                "Accept-Encoding": "gzip, deflate, br",
                "Connection": "keep-alive",
                "Upgrade-Insecure-Requests": "1",
                "Sec-Fetch-Dest": "document",
                "Sec-Fetch-Mode": "navigate",
                "Sec-Fetch-Site": "none",
                "Sec-Fetch-User": "?1"
            },
            extra_args=["--disable-blink-features=AutomationControlled", "--no-sandbox"],
            enable_stealth=True
        )

        async with AsyncWebCrawler(config=browser_cfg) as crawler:
            for attempt in range(3):
                try:
                    result = await crawler.arun(
                        url=url, 
                        config=CrawlerRunConfig(
                            extraction_strategy=strategy,
                            cache_mode=CacheMode.BYPASS,
                            page_timeout=40000, # 40 —Å–µ–∫
                            wait_until="domcontentloaded"
                        )
                    )
                    
                    if result.success and result.extracted_content:
                        clean_content = self._clean_json(result.extracted_content)
                        data = json.loads(clean_content)
                        if isinstance(data, list) and data:
                            data = data[0]
                        return data, result.html # Return HTML too!
                except Exception as e:
                    logger.warning(f"Failed to scrape {url} (Attempt {attempt+1}/3): {e}")
                    await asyncio.sleep(2 * (attempt + 1)) # Backoff
            
            logger.error(f"‚ùå All attempts failed for {url}")
        return None, None

    def merge_data(self, main_data: Dict, new_data: Dict) -> Dict:
        """–£–º–Ω–æ–µ —Å–ª–∏—è–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç universities.ts)."""
        if not new_data: 
            return main_data
        
        # –ü—Ä–æ—Å—Ç–æ–µ —Å–ª–∏—è–Ω–∏–µ: –±–µ—Ä–µ–º –Ω–µ-–ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ new_data, –µ—Å–ª–∏ –≤ main_data –Ω–µ—Ç –∏–ª–∏ –ø—É—Å—Ç–æ
        
        # description - –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É–µ–º –∏–ª–∏ –±–µ—Ä–µ–º –±–æ–ª–µ–µ –ø–æ–ª–Ω—ã–π
        if new_data.get('description') and len(new_data.get('description', '')) > len(main_data.get('description', '')):
            main_data['description'] = new_data['description']
        
        # foundedYear, ranking, studentCount - –±–µ—Ä–µ–º –Ω–µ–Ω—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        for key in ['foundedYear', 'ranking', 'studentCount', 'acceptanceRate']:
            if new_data.get(key) and (not main_data.get(key) or main_data.get(key) == 0):
                main_data[key] = new_data[key]
        
        # tuitionRange - –µ—Å–ª–∏ –µ—Å—Ç—å –º–∏–Ω –∏–ª–∏ –º–∞–∫—Å
        if 'tuitionRange' in new_data:
            if 'tuitionRange' not in main_data:
                main_data['tuitionRange'] = {'min': 0, 'max': 0}
            if new_data['tuitionRange'].get('min', 0) > 0:
                main_data['tuitionRange']['min'] = new_data['tuitionRange']['min']
            if new_data['tuitionRange'].get('max', 0) > 0:
                main_data['tuitionRange']['max'] = new_data['tuitionRange']['max']
        
        # programs - –æ–±—ä–µ–¥–∏–Ω—è–µ–º –±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ –∏–º–µ–Ω–∏
        if 'programs' in new_data and isinstance(new_data['programs'], list):
            if 'programs' not in main_data:
                main_data['programs'] = []
            
            existing_names = {p.get('name') for p in main_data.get('programs', []) if isinstance(p, dict)}
            for prog in new_data['programs']:
                if isinstance(prog, dict) and prog.get('name') and prog['name'] not in existing_names:
                    main_data['programs'].append(prog)
                    existing_names.add(prog['name'])
        
        # admissions - –æ–±—ä–µ–¥–∏–Ω—è–µ–º –º–∞—Å—Å–∏–≤—ã
        if 'admissions' in new_data:
            if 'admissions' not in main_data:
                main_data['admissions'] = {'deadline': [], 'requirements': [], 'scholarships': []}
            
            for key in ['deadline', 'requirements', 'scholarships']:
                if isinstance(new_data['admissions'].get(key), list):
                    existing_set = set(main_data['admissions'].get(key, []))
                    for item in new_data['admissions'][key]:
                        if item and item not in existing_set:
                            if key not in main_data['admissions']:
                                main_data['admissions'][key] = []
                            main_data['admissions'][key].append(item)
                            existing_set.add(item)
        
        # international - partners —ç—Ç–æ –ß–ò–°–õ–û, exchangePrograms —ç—Ç–æ –º–∞—Å—Å–∏–≤
        if 'international' in new_data:
            if 'international' not in main_data:
                main_data['international'] = {'partners': 0, 'exchangePrograms': []}
            
            # partners - –±–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ
            if isinstance(new_data['international'].get('partners'), int):
                main_data['international']['partners'] = max(
                    main_data['international'].get('partners', 0), 
                    new_data['international']['partners']
                )
            
            # exchangePrograms - –æ–±—ä–µ–¥–∏–Ω—è–µ–º –º–∞—Å—Å–∏–≤—ã
            if isinstance(new_data['international'].get('exchangePrograms'), list):
                existing_progs = set(main_data['international'].get('exchangePrograms', []))
                for prog in new_data['international']['exchangePrograms']:
                    if prog and prog not in existing_progs:
                        if 'exchangePrograms' not in main_data['international']:
                            main_data['international']['exchangePrograms'] = []
                        main_data['international']['exchangePrograms'].append(prog)
                        existing_progs.add(prog)
        
        # stats - –ø—Ä–æ—Å—Ç–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
        if 'stats' in new_data:
            if 'stats' not in main_data:
                main_data['stats'] = {'employmentRate': 0, 'researchOutput': 'Medium', 'studentSatisfaction': 0}
            
            for key in ['employmentRate', 'studentSatisfaction']:
                if new_data['stats'].get(key) and (not main_data['stats'].get(key) or main_data['stats'].get(key) == 0):
                    main_data['stats'][key] = new_data['stats'][key]
            
            if new_data['stats'].get('researchOutput') and new_data['stats']['researchOutput'] != 'Medium':
                main_data['stats']['researchOutput'] = new_data['stats']['researchOutput']
        
        return main_data

    def _norm_url(self, u: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è URL –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è."""
        if not u:
            return ""
        u = u.strip()
        return u[:-1] if u.endswith("/") else u

    def _extract_year(self, text: str) -> int | None:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≥–æ–¥–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
        if not text:
            return None
        m = re.search(r"(18\d{2}|19\d{2}|20\d{2})", text)
        return int(m.group(1)) if m else None

    def _extract_int(self, text: str) -> int | None:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–ª–æ–≥–æ —á–∏—Å–ª–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
        if not text:
            return None
        s = re.sub(r"[^\d]", "", text)
        return int(s) if s else None

    def _extract_percent(self, text: str) -> int | None:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
        if not text:
            return None
        m = re.search(r"(\d{1,3})\s*%", text)
        if not m:
            return None
        v = int(m.group(1))
        return v if 0 <= v <= 100 else None

    def _degree_map(self, degree_level: str | None) -> str:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —É—Ä–æ–≤–Ω—è —Å—Ç–µ–ø–µ–Ω–∏."""
        if not degree_level:
            return "Bachelor"
        d = degree_level.lower()
        if "–º–∞–≥" in d or "master" in d:
            return "Master"
        if "–¥–æ–∫" in d or "phd" in d:
            return "PhD"
        return "Bachelor"

    def _build_description(self, uni: dict) -> str | None:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞ –∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø–∞—Ä—Å–µ—Ä–∞."""
        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –æ–±–µ–∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä: —Å—Ç–∞—Ä–æ–π (about) –∏ –Ω–æ–≤–æ–π (about_university)
        about = uni.get("about_university") or uni.get("about") or {}
        admissions = uni.get("admissions") or {}
        intl = uni.get("international_cooperation") or uni.get("international") or {}
        tour = uni.get("tour_3d") or uni.get("virtual_tour") or {}
        stats = uni.get("stats") or {}

        parts = []

        if about.get("mission"):
            parts.append(f"–ú–∏—Å—Å–∏—è: {about['mission']}")
        if about.get("history_summary") or about.get("history"):
            history = about.get("history_summary") or about.get("history")
            parts.append(f"–ò—Å—Ç–æ—Ä–∏—è: {history}")
        if about.get("leadership"):
            parts.append(f"–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ: {about['leadership']}")
        if about.get("achievements"):
            achievements = about["achievements"]
            if isinstance(achievements, list):
                ach = "; ".join([str(a) for a in achievements if a])[:500]  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã
                if ach:
                    parts.append(f"–î–æ—Å—Ç–∏–∂–µ–Ω–∏—è: {ach}")

        # Admissions - –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –æ–±–µ–∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä
        req = admissions.get("requirements")
        if req:
            req_text = req if isinstance(req, str) else str(req)
            parts.append(f"–ü–æ—Å—Ç—É–ø–ª–µ–Ω–∏–µ (—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è): {req_text[:200]}")
        
        deadlines = admissions.get("deadlines")
        if deadlines:
            if isinstance(deadlines, list):
                deadlines = "; ".join([str(d) for d in deadlines if d])
            parts.append(f"–°—Ä–æ–∫–∏ –ø—Ä–∏—ë–º–∞: {str(deadlines)[:200]}")
        
        scholarships = admissions.get("scholarships") or admissions.get("scholarships_fin_aid")
        if scholarships:
            sch_text = scholarships if isinstance(scholarships, str) else str(scholarships)
            parts.append(f"–ì—Ä–∞–Ω—Ç—ã/—Å–∫–∏–¥–∫–∏/—Å—Ç–∏–ø–µ–Ω–¥–∏–∏: {sch_text[:200]}")
        
        tuition = admissions.get("tuition_info")
        if tuition:
            parts.append(f"–û–ø–ª–∞—Ç–∞/—Å—Ç–æ–∏–º–æ—Å—Ç—å: {tuition[:200]}")

        # Virtual tour - –æ–±–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        if tour.get("is_available") and tour.get("url"):
            parts.append(f"3D/–≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π —Ç—É—Ä: {tour['url']}")
        elif tour.get("tour_url"):
            parts.append(f"3D/–≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π —Ç—É—Ä: {tour['tour_url']}")

        # International partners - –æ–±–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        partners = intl.get("partner_universities") or intl.get("partners") or []
        if partners and isinstance(partners, list):
            partners_text = ', '.join([str(p) for p in partners[:10] if p])
            if partners_text:
                parts.append(f"–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –ø–∞—Ä—Ç–Ω—ë—Ä—ã (–ø—Ä–∏–º–µ—Ä—ã): {partners_text}")

        # Stats
        if stats.get("student_count"):
            parts.append(f"–°—Ç—É–¥–µ–Ω—Ç–æ–≤: {stats['student_count']}")
        if stats.get("employment_rate"):
            parts.append(f"–¢—Ä—É–¥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {stats['employment_rate']}")

        return "\n\n".join(parts) if parts else None

    def update_universities_ts(self, ts_path: str = "data/universities.ts", add_missing: bool = False):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ universities.ts —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ –ø–∞—Ä—Å–µ—Ä–∞."""
        ts_file = Path(ts_path)
        if not ts_file.exists():
            raise FileNotFoundError(f"universities.ts not found at: {ts_file.resolve()}")

        content = ts_file.read_text(encoding="utf-8")

        # –í—ã—Ç–∞—â–∏—Ç—å –º–∞—Å—Å–∏–≤ –∏–∑ `export const universities: University[] = [ ... ];`
        m = re.search(r"export const universities:\s*University\[\]\s*=\s*(\[[\s\S]*?\]);\s*$", content)
        if not m:
            raise ValueError("Cannot find `export const universities: University[] = [...]` in universities.ts")

        arr_text = m.group(1)
        arr_clean = re.sub(r",\s*([}\]])", r"\1", arr_text)  # —É–±—Ä–∞—Ç—å trailing commas –¥–ª—è JSON
        current = json.loads(arr_clean)

        by_site = {}
        for obj in current:
            site = self._norm_url(obj.get("website", ""))
            if site:
                by_site[site] = obj

        updated = 0
        added = 0

        for uni in self.results:
            site = self._norm_url(uni.get("website", ""))
            if not site:
                continue

            existing = by_site.get(site)
            if not existing and not add_missing:
                continue

            if not existing:
                # —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç, –µ—Å–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–æ add_missing
                uid = "uni-" + hashlib.sha1(site.encode("utf-8")).hexdigest()[:16]
                existing = {
                    "id": uid,
                    "name": uni.get("university_name") or "Unknown University",
                    "shortName": (uni.get("university_name") or "Uni")[:10],
                    "location": uni.get("city") or "Kazakhstan",
                    "description": "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è.",
                    "foundedYear": 2000,
                    "ranking": 0,
                    "studentCount": 0,
                    "acceptanceRate": 0,
                    "tuitionRange": {"min": 0, "max": 0},
                    "website": site,
                    "logoUrl": f"/logos/{uid}.png",
                    "imageUrl": "https://images.unsplash.com/photo-1541339907198-e08756dedf3f?q=80&w=1000&auto=format&fit=crop",
                    "type": "state",
                    "programs": [],
                    "admissions": {"deadline": "", "requirements": [], "scholarships": []},
                    "international": {"partners": 0, "exchangePrograms": []},
                    "stats": {"employmentRate": 0, "researchOutput": "Medium", "studentSatisfaction": 0},
                }
                current.append(existing)
                by_site[site] = existing
                added += 1

            # --- –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–ª–µ–π –∏–∑ –ø–∞—Ä—Å–µ—Ä–∞ ---
            if uni.get("city"):
                existing["location"] = uni["city"]

            desc = self._build_description(uni)
            if desc:
                existing["description"] = desc

            founded = self._extract_year((uni.get("about") or {}).get("history_summary"))
            if founded:
                existing["foundedYear"] = founded

            # programs - –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –æ–±–µ–∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä
            progs = uni.get("academic_programs") or []
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (program_examples)
            if isinstance(progs, dict) and progs.get("program_examples"):
                program_examples = progs.get("program_examples", [])
                if program_examples:
                    new_programs = []
                    uid = existing["id"]
                    for i, pname in enumerate(program_examples[:20]):
                        if not pname or not isinstance(pname, str):
                            continue
                        pname = pname.strip()
                        
                        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                        degree = "Bachelor"
                        pname_lower = pname.lower()
                        if any(word in pname_lower for word in ["–º–∞–≥–∏—Å—Ç—Ä", "master", "ma ", "msc", "graduate"]):
                            degree = "Master"
                        elif any(word in pname_lower for word in ["–¥–æ–∫—Ç–æ—Ä–∞–Ω—Ç", "phd", "postgraduate"]):
                            degree = "PhD"
                        
                        new_programs.append({
                            "id": f"{uid}-p-{i}",
                            "name": pname,
                            "degree": degree,
                            "duration": "4 years",
                            "tuition": 0,
                            "language": "English"
                        })
                    if new_programs:
                        existing["programs"] = new_programs
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∞—Ä–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (—Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π)
            elif isinstance(progs, list) and progs:
                new_programs = []
                uid = existing["id"]
                for i, p in enumerate(progs[:20]):
                    if not isinstance(p, dict):
                        continue
                    pname = (p.get("program_name") or "").strip()
                    if not pname:
                        continue
                    new_programs.append({
                        "id": f"{uid}-p-{i}",
                        "name": pname,
                        "degree": self._degree_map(p.get("degree_level")),
                        "duration": "4 years",
                        "tuition": 0,
                        "language": "English"
                    })
                if new_programs:
                    existing["programs"] = new_programs

            # admissions
            adm = uni.get("admissions") or {}
            req = adm.get("requirements")
            if req:
                existing["admissions"]["requirements"] = [req]
            if adm.get("deadlines"):
                existing["admissions"]["deadline"] = adm["deadlines"]
            if adm.get("scholarships"):
                existing["admissions"]["scholarships"] = [adm["scholarships"]]

            # international
            intl = uni.get("international") or {}
            partners = intl.get("partners") or []
            if partners:
                existing["international"]["partners"] = len(partners)
            if intl.get("exchange_programs"):
                existing["international"]["exchangePrograms"] = [intl["exchange_programs"]] if isinstance(intl["exchange_programs"], str) else intl["exchange_programs"]

            # stats
            st = uni.get("stats") or {}
            emp = self._extract_percent(st.get("employment_rate"))
            if emp is not None:
                existing["stats"]["employmentRate"] = emp
            sc = self._extract_int(st.get("student_count"))
            if sc is not None:
                existing["studentCount"] = sc

            updated += 1

        # –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Ñ–∞–π–ª: —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å—ë –¥–æ `export const universities...`, –∑–∞—Ç–µ–º –Ω–æ–≤—ã–π –º–∞—Å—Å–∏–≤
        prefix = content[:m.start()]
        new_block = "export const universities: University[] = " + json.dumps(current, ensure_ascii=False, indent=4) + ";\n"
        ts_file.write_text(prefix + new_block, encoding="utf-8")

        logger.info(f"üß© universities.ts updated={updated}, added={added}, path={ts_file.resolve()}")

    async def process_university(self, uni_info: Dict):
        """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞."""
        name = uni_info['name']
        url = uni_info['url']
        
        # –û—á–∏—Å—Ç–∫–∞ URL –µ—Å–ª–∏ –æ–Ω –≤ —Ñ–æ—Ä–º–∞—Ç–µ markdown [url](url)
        match = re.search(r'\((https?://[^)]+)\)', url)
        if match:
             url = match.group(1)
        elif url.startswith('[') and '](' in url: # [url](url) –±–µ–∑ http?
             match_alt = re.search(r'\(([^)]+)\)', url)
             if match_alt: url = match_alt.group(1)

        logger.info(f"üöÄ –°—Ç–∞—Ä—Ç: {name} ({url})")

        # 1. –ü–∞—Ä—Å–∏–Ω–≥ –≥–ª–∞–≤–Ω–æ–π (Prioritize Main Data)
        main_data, main_html = await self.scrape_page(url)
        if not main_data:
            logger.error(f"‚ùå Main page failed: {name}")
            return
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –±–∞–∑–æ–≤—ã–µ –ø–æ–ª—è, –µ—Å–ª–∏ AI –ø—Ä–æ–ø—É—Å—Ç–∏–ª
        main_data['university_name'] = name
        main_data['website'] = url
        main_data['city'] = uni_info['city']
        main_data['_scraped_at'] = datetime.now().isoformat()

        await asyncio.sleep(5) # Delay before deep scraping

        # 2. –ü–æ–∏—Å–∫ —Å—Å—ã–ª–æ–∫ (Reuse HTML if available!)
        try:
            links = await self.discover_links(url, main_html)
            logger.info(f"Found {len(links)} links for {name}")
        except Exception as e:
            logger.warning(f"Link discovery failed: {e}")
            links = []

        # 3. –ü–∞—Ä—Å–∏–Ω–≥ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü (–º–∞–∫—Å–∏–º—É–º 3)
        tasks = []
        processed_types = set()
        
        for link in links:
            l_type = link.get('section_type')
            l_url = link.get('url')
            
            if l_type in processed_types or not l_url.startswith('http'):
                continue
                
            processed_types.add(l_type)
            logger.info(f"  -> –ü–∞—Ä—Å–∏–Ω–≥ —Ä–∞–∑–¥–µ–ª–∞ {l_type}: {l_url}")
            
            # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, —á—Ç–æ–±—ã –Ω–µ –ø–æ–ª–æ–∂–∏—Ç—å —Å–µ—Ä–≤–µ—Ä –∏–ª–∏ –±—Ä–∞—É–∑–µ—Ä
            sub_data, _ = await self.scrape_page(l_url)
            if sub_data:
                main_data = self.merge_data(main_data, sub_data)
            
            await asyncio.sleep(2) # –í–µ–∂–ª–∏–≤–æ—Å—Ç—å
            if len(processed_types) >= 3: break

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –∑–∞–ø–∏—Å—å –µ—Å–ª–∏ –µ—Å—Ç—å
        self.results = [r for r in self.results if r.get('website') != url]
        self.results.append(main_data)
        self.save_to_file()
        logger.info(f"‚úÖ –ì–æ—Ç–æ–≤–æ: {name}")

    def save_to_file(self):
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON –¥–ª—è –¥–µ–±–∞–≥–∞
        with open(self.output_file, 'w', encoding='utf-8') as f:
            json.dump({
                "last_update": datetime.now().isoformat(),
                "universities": self.results
            }, f, ensure_ascii=False, indent=2)
        
        # –¢–µ–ø–µ—Ä—å –æ–±–Ω–æ–≤–ª—è–µ–º universities.ts –Ω–∞–ø—Ä—è–º—É—é
        try:
            self.update_universities_ts("data/universities.ts", add_missing=False)
            logger.info("üîÑ universities.ts updated from scraper results")
        except Exception as e:
            logger.warning(f"Failed to update universities.ts: {e}")

    async def run_all(self, single_uni_info: Optional[Dict] = None):
        if single_uni_info:
            await self.process_university(single_uni_info)
        else:
            for uni in KAZAKHSTAN_UNIVERSITIES:
                await self.process_university(uni)
                await asyncio.sleep(2) # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –≤—É–∑–∞–º–∏

# ---------------------------------------------------------
# 5. –ó–ê–ü–£–°–ö
# ---------------------------------------------------------

async def main():
    import argparse
    parser = argparse.ArgumentParser(description="UniDataHub Scraper")
    parser.add_argument("--url", help="Scrape a single university by URL")
    parser.add_argument("--name", help="Name of the university (used if --url is provided)")
    args = parser.parse_args()

    # 1. –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á –∏–∑ ENV
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω GOOGLE_API_KEY –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
        print("–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env –∏–ª–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ export GOOGLE_API_KEY='...'")
        return

    # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    scraper = UniversityScraper(api_key=api_key)
    
    # 3. –ó–∞–ø—É—Å–∫
    print(f"ü§ñ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ —Å –º–æ–¥–µ–ª—å—é {scraper.provider}")
    
    if args.url:
        uni_info = {
            'name': args.name or "Unknown University",
            'url': args.url,
            'city': 'Unknown'
        }
        print(f"üéØ Single target mode: {uni_info['name']}")
        await scraper.run_all(single_uni_info=uni_info)
    else:
        await scraper.run_all()

    print("‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω! universities.ts –æ–±–Ω–æ–≤–ª—ë–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.")

if __name__ == "__main__":
    asyncio.run(main())
